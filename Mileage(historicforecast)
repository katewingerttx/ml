import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random
import math
import time
start = time.time()

# write data into correct form
df = pd.read_excel(r'L:\$Projects\Jav\Neural Networks\3 Mileage_Data.xlsx', sheet_name='Intermodal 53 Ft 2YearPredictio')
array = df.to_numpy()
# Data Standardization
array[:,0] = array[:,0] - 2010
array[:,2] = array[:,2] / 100000000
array[:,3] = array[:,3] / 100000000
array[:,4] = array[:,4] / 100000000
array[:,5] = array[:,5] / 100000000
 
def getMileageData(numIn, rw): # manipulate array into useful data form
    mileageData = np.zeros(shape=(len(array)-rw-12,numIn+2), dtype=np.float32)
    for i in range(len(array)-rw-12):
        for j in range(rw):
            mileageData[i,j] = array[i+j,2] # first [sizeRollingWindow] mileage datapoints as inputs
            mileageData[i,rw+j+1] = array[i+j,3] # first [sizeRollingWindow] FIS datapoints as inputs
        mileageData[i,rw] = array[i+rw,5] # FIS datapoint prediction for month to predict
        for j in range(12):
            if array[i+rw,1] == j+1:
                mileageData[i,(rw*2)+1+j] = 1 # january = true
        mileageData[i,(rw*2)+13] = array[i+rw,0] # year of prediction
        mileageData[i,(rw*2)+14] = array[i+rw,2] # mileage datapoint to predict
        mileageData[i,(rw*2)+15] = array[i+rw,4] # historic mileage prediction
    return mileageData

class NeuralNetwork:
    
    def __init__(self, numIn, numHid, numOut, seed):
        
        self.numInput = numIn # number of inputs
        self.numHidden = numHid # number of hidden nodes
        self.numOutput = numOut # number of outputs
        
        self.iNodes = np.zeros(shape=[self.numInput], dtype=np.float32) # creates input nodes
        self.hNodes = np.zeros(shape=[self.numHidden], dtype=np.float32) # creates hidden nodes
        self.oNodes = np.zeros(shape=[self.numOutput], dtype=np.float32) # creates output nodes
    
        self.ihWeights = np.zeros(shape=[self.numInput,self.numHidden], dtype=np.float32) # array of input x hidden weights
        self.hoWeights = np.zeros(shape=[self.numHidden,self.numOutput], dtype=np.float32) # array of hidden x output weights
        
        self.hBiases = np.zeros(shape=[self.numHidden], dtype=np.float32) # array of hidden node biases
        self.oBiases = np.zeros(shape=[self.numOutput], dtype=np.float32) # array of output biases
        
        self.rnd = random.Random(seed) # allows multiple instances
        self.initializeWeights()
        
    def setWeights(self, weights): # transform weights array into separate arrays based on where they are applied so they can be used and manipulated
            
        idx = 0
        for i in range(self.numInput):
            for j in range(self.numHidden):
                self.ihWeights[i,j] = weights[idx]
                idx += 1
                
        for j in range(self.numHidden):
            self.hBiases[j] = weights[idx]
            idx += 1
                
        for j in range(self.numHidden):
            for k in range(self.numOutput):
                self.hoWeights[j,k] = weights[idx]
                idx += 1
                
        for k in range(self.numOutput):
            self.oBiases[k] = weights[idx]
            idx += 1
                    
    def getWeights(self): # return weights/biases into one array after use and manipulation
        
        tw = self.totalWeights() # determine number of weights/biases
        result = np.zeros(shape=[tw], dtype=np.float32)
        idx = 0 # points into result
        
        for i in range(self.numInput):
            for j in range(self.numHidden):
                result[idx] = self.ihWeights[i,j]
                idx += 1
                
        for j in range(self.numHidden):
            result[idx] = self.hBiases[j]
            idx += 1
            
        for j in range(self.numHidden):
            for k in range(self.numOutput):
                result[idx] = self.hoWeights[j,k]
                idx += 1
            
        for k in range(self.numOutput):
            result[idx] = self.oBiases[k]
            idx += 1
            
        return result
        
    def initializeWeights(self): # set initial random weights to start
        
        numWts = self.totalWeights()
        wts = np.zeros(shape=[numWts], dtype=np.float32)
        lo = -0.5; hi = 0.5
        for idx in range(len(wts)):
            wts[idx] = (hi-lo) * self.rnd.random() + lo
        self.setWeights(wts)
        
    def computeOutputs(self, xValues): # forward propagation
        
        hSums = np.zeros(shape=[self.numHidden], dtype=np.float32) # temporary sum variable
        oSums = np.zeros(shape=[self.numOutput], dtype=np.float32) # temporary sum variable
        
        for i in range(self.numInput):
            self.iNodes[i] = xValues[i] # start with current rows input values
            
        for j in range(self.numHidden):
            for i in range(self.numInput):
                hSums[j] += self.iNodes[i] * self.ihWeights[i,j] # multiply input nodes by the weight values
        
        for j in range(self.numHidden):
            hSums[j] += self.hBiases[j] # add bias values
            
        for j in range(self.numHidden):
            self.hNodes[j] = self.hypertan(hSums[j]) # run values through activation function: use tanh
            
        for k in range(self.numOutput):
            for j in range(self.numHidden):
                oSums[k] += self.hNodes[j] * self.hoWeights[j,k] # multiply hidden nodes by weight values
        
        for k in range(self.numOutput):
            oSums[k] += self.oBiases[k] # add bias values
            
        self.oNodes = oSums # not using another activation function here; previously experimented with but only useful for classification NN

        result = np.zeros(shape=[self.numOutput], dtype=np.float32)
        for k in range(self.numOutput): 
            result[k] = self.oNodes[k]

        return result

    def train(self, trainData, maxEpochs, learnRate, errUpdate, momentum, resultsArray):
        
        hoGrads = np.zeros(shape=[self.numHidden, self.numOutput], dtype=np.float32) # hidden-to-output weights gradients
        obGrads = np.zeros(shape=[self.numOutput], dtype=np.float32) # output node bias gradients
        ihGrads = np.zeros(shape=[self.numInput, self.numHidden], dtype=np.float32) # input-to-hidden weights gradients
        hbGrads = np.zeros(shape=[self.numHidden], dtype=np.float32) # hidden bias gradients
        
        oSignals = np.zeros(shape=[self.numOutput], dtype=np.float32) # output signals: gradients w/o assoc. input terms
        hSignals = np.zeros(shape=[self.numHidden], dtype=np.float32) # hidden signals: gradients w/o assoc. input terms
        
        ih_prev_weights_delta = np.zeros(shape=[self.numInput, self.numHidden], dtype=np.float32) # saved delta values for momentum
        h_prev_biases_delta = np.zeros(shape=[self.numHidden], dtype=np.float32) # saved delta values for momentum
        ho_prev_weights_delta = np.zeros(shape=[self.numHidden, self.numOutput], dtype=np.float32) # saved delta values for momentum
        o_prev_biases_delta = np.zeros(shape=[self.numOutput], dtype=np.float32) # saved delta values for momentum
        
        epoch = 0
        self.numTrainItems = len(trainData)
        x_values = np.zeros(shape=[self.numInput], dtype=np.float32) # array to insert current input values
        output = np.zeros(shape=[self.numOutput], dtype=np.float32) # array to insert current output
        actual_values = np.zeros(shape=[self.numOutput], dtype=np.float32) # array to insert current actual output

        indices = np.arange(self.numTrainItems) # [0, 1, 2, . . n-1] 
        err = np.full(shape=[maxEpochs//errUpdate + 1], fill_value = 1000, dtype=np.float32) # array to keep track of all error values
        self.resultsCounter = 0
        
        while epoch <= maxEpochs:
            
            if epoch == 0:
                time1 = time.time() # timestamp used to estimate training time
            
            self.rnd.shuffle(indices) # scramble order of training items
            
            for ii in range(self.numTrainItems):
                idx = indices[ii]
                
                for j in range(self.numInput):
                    x_values[j] = trainData[idx,j] # get the current input values
                for j in range(self.numOutput):
                    actual_values[j] = trainData[idx,j+self.numInput] # get current target values
                self.computeOutputs(x_values) # results stored internally
                
            # Backpropagation
                
                #1. compute output node signals
                for k in range(self.numOutput):
                    deriv = 1 # derivative is one because I chose not to use an activation function for the outputs
                    oSignals[k] = deriv * (self.oNodes[k] - actual_values[k]) # multiply derivative by error
                
                #2. compute hidden-to-output weight gradients using output signals
                for j in range(self.numHidden):
                    for k in range(self.numOutput):
                        hoGrads[j,k] = oSignals[k] * self.hNodes[j]
                        
                #3. compute output node bias gradients using output signals
                for k in range(self.numOutput):
                    obGrads[k] = oSignals[k] 
                    
                #4. compute hidden node signals
                for j in range(self.numHidden):
                    sum = 0.0
                    for k in range(self.numOutput):
                        sum += oSignals[k] * self.hoWeights[j,k]
                    deriv = (1 - self.hNodes[j]) * (1 + self.hNodes[j]) # derivative of tanh function used to compute output values
                    hSignals[j] = deriv * sum
                    
                #5. compute input-to-hidden weight gradients using hidden signals
                for i in range(self.numInput):
                    for j in range(self.numHidden):
                        ihGrads[i,j] = hSignals[j] * self.iNodes[i]
                        
                #6. compute hidden node bias gradients using hidden signals
                for j in range(self.numHidden):
                    hbGrads[j] = hSignals[j]
                
            # update weights and biases using the gradients and momentum
                
                #1. update input-to-hidden weights
                for i in range(self.numInput):
                    for j in range(self.numHidden):
                        delta = -1.0 * learnRate * ihGrads[i,j]
                        self.ihWeights[i,j] += delta
                        self.ihWeights[i,j] += momentum * ih_prev_weights_delta[i,j] # momentum
                        ih_prev_weights_delta[i,j] = delta # save delta for next iteration
                    
                #2. update hidden node biases
                for j in range(self.numHidden):
                    delta = -1.0 * learnRate * hbGrads[j]
                    self.hBiases[j] += delta
                    self.hBiases[j] += momentum * h_prev_biases_delta[j]
                    h_prev_biases_delta[j] = delta 
                    
                #3. update hidden-to-output weights
                for j in range(self.numHidden):
                    for k in range(self.numOutput):
                        delta = -1.0 * learnRate * hoGrads[j,k]
                        self.hoWeights[j,k] += delta
                        self.hoWeights[j,k] += momentum * ho_prev_weights_delta[j,k]
                        ho_prev_weights_delta[j,k] = delta
                    
                #4. update output node biases
                for k in range(self.numOutput):
                    delta = -1.0 * learnRate * obGrads[k]
                    self.oBiases[k] += delta
                    self.oBiases[k] += momentum * o_prev_biases_delta[k]
                    o_prev_biases_delta[k] = delta
               
            if epoch == 0:
                epochTime = (time.time() - time1) # time to complete the first epoch
                print("\nEstimated training time: %.1f minutes\n" % ((epochTime * maxEpochs) / 60))
            
            if epoch % errUpdate == 0: # run every 50 epochs 
                mape = self.MAPE(trainData)
                if all(x > mape for x in err): # determine weights with least error
                    self.finalWeights = self.getWeights()
                    print("epoch = " + str(epoch) +" mape = %0.4f (best weights)" % mape)
                else:
                    print("epoch = " + str(epoch) +" mape = %0.4f " % mape)
                err[epoch//errUpdate] = mape
               
                # to export all outputs to excel
                #resultsArray[self.resultsCounter,0] = epoch 
                #resultsArray[self.resultsCounter,1] = mape
                #self.resultsCounter += 1
            
            # print percent complete with training
            percent = ((epoch / maxEpochs) * 100)
            percentComplete = "Percent Complete: %f%%" % percent
            print("Percent Complete: %.3f%%" % percent, end="\r")    
            
            epoch += 1
        
            
        # end while
        
        # print error plot
        x = np.arange(maxEpochs//errUpdate + 1)
        plt.plot(x,err)
        plt.xlabel('Epochs / %d' % errUpdate)
        plt.ylabel('MeanSquaredError')
        plt.show()
               
        result = self.getWeights()
        return result
    # end train
    
    def accuracy(self, trainData, rw, howClose, resultsArray): 
        num_correct = 0; num_wrong = 0
        self.setWeights(self.finalWeights) # use weights with the least error
        
        x_values = np.zeros(shape=[self.numInput], dtype=np.float32) # array to insert current input values
        actual_values = np.zeros(shape=[self.numOutput], dtype=np.float32) # array to insert current actual output 
        dataLength = len(trainData)
        
        for i in range(dataLength): # walk through each data item
            for j in range(self.numInput): # peel off input values from current data row
                x_values[j] = trainData[i,j]
            for j in range(self.numOutput): # peel off target values from current data row
                actual_values[j] = trainData[i,self.numInput]
            
            output_values = self.computeOutputs(x_values) # computed output values
            
            if (np.absolute(output_values[0] - actual_values[0]) < (howClose*actual_values[0])): # within a certain amount to be correct
                num_correct += 1
            else:
                num_wrong += 1
                
            for k in range(12): # determine month
                if trainData[i,(rw*2)+1+k] == 1:
                    month = k+1
            year = (trainData[i,(rw*2)+13])+2010 # determine year
            
            print("%d\t%d:\t%.5f\t%.5f\t%2.1f %%" % (year, month, actual_values[0], output_values[0], (np.absolute((actual_values[0] - output_values[0]) / actual_values[0])*100)))
            
            # to export all outputs to excel
            #resultsArray[self.resultsCounter,0] = year
            #resultsArray[self.resultsCounter,1] = month
            #resultsArray[self.resultsCounter,2] = actual_values[0]
            #resultsArray[self.resultsCounter,3] = output_values[0]
            #resultsArray[self.resultsCounter,4] = (np.absolute((actual_values[0] - output_values[0]) / actual_values[0])*100)
            #self.resultsCounter += 1
        
        percentCorrect = (num_correct) / (num_correct + num_wrong) 
        
        return percentCorrect

    def MAPE(self, tdata):
        sumPercentError = 0.0
        
        x_values = np.zeros(shape=[self.numInput], dtype=np.float32) # array to insert current input values
        actual_values = np.zeros(shape=[self.numOutput], dtype=np.float32) # array to insert current actual output
        
        for ii in range(self.numTrainItems): # walk through each data item
            for jj in range(self.numInput): # peel off input values from current data row
                x_values[jj] = tdata[ii,jj]
            for jj in range(self.numOutput): # peel of target values from current data row
                actual_values[jj] = tdata[ii,jj+self.numInput]
                
            output_values = self.computeOutputs(x_values) # computed output values
            
            for j in range(self.numOutput):
                err = np.absolute(actual_values[j] - output_values[j]) / actual_values[j]
                sumPercentError += err
                
        return sumPercentError / self.numTrainItems

    def twoYearForecast(self, forecastMileageData, rw, maxEpochs, learnRate, errUpdate, momentum, resultsArray):
        x_values = np.zeros(shape=[self.numInput], dtype=np.float32)
        sumErrorPred = 0
        sumErrorHist = 0
        
        print("\n", len(forecastMileageData), " Months of Forecasted Data")
        
        for i in range(len(forecastMileageData)):
            for j in range(self.numInput): # peel off input values 
                x_values[j] = forecastMileageData[i,j]
            output_values = self.computeOutputs(x_values)
            for k in range(rw):
                if (i+k+1) < len(forecastMileageData):
                    forecastMileageData[i+k+1,rw-k-1] = output_values
            for k in range(12): # determine month
                if forecastMileageData[i,(rw*2)+1+k] == 1:
                    month = k+1
            year = (forecastMileageData[i,(rw*2)+13])+2010 # determine year
            historic_values = forecastMileageData[i,(rw*2)+15] # determine historic prediction value
            actual_values = forecastMileageData[i,(rw*2)+14] # determine actual value
            print("%d\t%d:\t%.5f\t%.5f\t%2.1f %%%.5f\t%2.1f %%" % (year, month, actual_values, output_values, (np.absolute((actual_values - output_values) / actual_values)*100), historic_values, (np.absolute((actual_values - historic_values) / actual_values)*100)))
        
            errPred = (np.absolute((actual_values - output_values) / actual_values)*100)
            errHist = (np.absolute((actual_values - historic_values) / actual_values)*100)
        
            resultsArray[self.resultsCounter,0] = year
            resultsArray[self.resultsCounter,1] = month
            resultsArray[self.resultsCounter,2] = actual_values
            resultsArray[self.resultsCounter,3] = output_values
            resultsArray[self.resultsCounter,4] = errPred
            resultsArray[self.resultsCounter,5] = historic_values
            resultsArray[self.resultsCounter,6] = errHist
            self.resultsCounter += 1
            
            sumErrorPred += errPred
            sumErrorHist += errHist
        
        # export to excel to check getMileageData() 
        writer = pd.ExcelWriter('C:\\Users\\bmpkpw\\Desktop\\Kate Winger\\Mileage\\Results\\mileageDataframe3.xlsx')
        data = pd.DataFrame(forecastMileageData)
        data.to_excel(writer)
        writer.save()
        
        impr = sumErrorHist - sumErrorPred
        avgImpr = impr / len(forecastMileageData)
        
        return impr, avgImpr
        
    def hypertan(self,x):
        if x < -20.0:
            return -1.0
        elif x > 20.0:
            return 1.0
        else:
            return math.tanh(x)
    
    def totalWeights(self):
        tw = (self.numInput * self.numHidden) + (self.numHidden * self.numOutput) + self.numHidden + self.numOutput
        return tw

# end class NeuralNetwork




def main():
    # Variables to determine by trial and error: 
    numHid = 19 # number of neurons in hidden layer
    maxEpochs = 2000 # number of interations
    learnRate = .01 # how quickly the program trains    
    
    sizeRollingWindow = 2 # number of monthly datapoints used for predictions    
    numIn = (sizeRollingWindow*2)+14 # number of inputs
    numOut = 1 # number of outputs (predict next mileage number)
    
#    print("\nBegin time series with raw mileage data ")
    mileageData = getMileageData(numIn, sizeRollingWindow)
    lenData = len(mileageData)
    
# export to excel to check getMileageData() 
    writer = pd.ExcelWriter('L:\\$Projects\\Jav\\Neural Networks\\mileageDataframe2.xlsx')
    data = pd.DataFrame(mileageData)
    data.to_excel(writer)
    writer.save()

    sizeForecast = 28 # choose how many months will be forecasted
    trainMileageData = mileageData[0:(lenData-sizeForecast),:] # split data into train and test
    forecastMileageData = mileageData[(lenData-sizeForecast):lenData,:]
    np.set_printoptions(formatter = {'float': '{: 0.5f}'.format})
      
    print("\nCreating a %d-%d-%d neural network " % (numIn, numHid, numOut))
    nn = NeuralNetwork(numIn, numHid, numOut, seed=0)
    
    errUpdate = 50 # how often to print an error update
    momentum = 0 # momentum value
    print("\nSetting maxEpochs = " + str(maxEpochs))
    print("Setting learning rate = %0.3f " % learnRate)
    
    # to export all outputs to excel sheet
    # length = math.floor((maxEpochs/errUpdate) + len(trainMileageData) + len(testMileageData) + 1)
    
    # to export only results needed to create graphs
    length = len(forecastMileageData)
    
    resultsArray = np.zeros(shape=[length,7], dtype=np.float32) # array to insert current input values
    
    print("\nStarting training...")
    nn.train(trainMileageData, maxEpochs, learnRate, errUpdate, momentum, resultsArray)
    print("Training complete. \n")
    
    print("Training year-month-actual-predicted: ")
    howClose = .02 # within what percentage of error is considered correct/acceptable
    acc = nn.accuracy(trainMileageData, sizeRollingWindow, howClose, resultsArray)
    
    impr, avgImpr = nn.twoYearForecast(forecastMileageData, sizeRollingWindow, maxEpochs, learnRate, errUpdate, momentum, resultsArray)
    
    # export results to excel 
    writer = pd.ExcelWriter('L:\\$Projects\\Jav\\Neural Networks\\mileageDataResults2.xlsx')
    data = pd.DataFrame(resultsArray)
    data.to_excel(writer)
    writer.save()
    
    print("\nSum of Percent Error Improvement on %d-item validation data: %0.2f%%" % (len(forecastMileageData), impr))
    print("\nAverage Monthly Percent Error Improvement: %0.2f%%" % avgImpr)
    print("\nEnd \n")
    
    # end of code     
main()
print("Run Time: %.1f minutes" % ((time.time() - start) / 60))
